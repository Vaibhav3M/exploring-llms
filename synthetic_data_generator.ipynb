{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcbf162-873f-4609-807b-5976e32a3648",
   "metadata": {},
   "source": [
    "# Synthetic dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00dfc19-c054-4c1f-b6af-c98bb05bdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a963c5-5f74-429d-8e0c-76a43ef6e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b44bdc2-0903-4108-b5dc-f2f7a2fb9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "                    You are a dataset generation assistant specializing in creating high-quality synthetic datasets for AI training.\n",
    "                    Ensure data is realistic, diverse, and domain-specific.\n",
    "                    Do not include personally identifiable information (PII).\n",
    "                    Maintain logical consistency in relationships between fields.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d99fb5-5094-405c-8838-73e5d5b7c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt_tabular(business_problem, dataset_format, file_format, num_samples):\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    The business problem is: {business_problem}. \\n\n",
    "    The dataset is expected to be in {dataset_format}. \n",
    "    For the dataset types such as tabular or time series implement python code for creating the dataset.\n",
    "    If the generated dataset contains several entities, i.e. products, users, write the output for these entities into separate files. \n",
    "    The dependencies for python code should include only standard python libraries such as numpy, pandas and built-in libraries. \n",
    "    The output dataset is stored as a {file_format} file and contains {num_samples} samples. \\n    \n",
    "    \"\"\"\n",
    "\n",
    "def generate_user_prompt_text(business_problem, dataset_format, file_format):\n",
    "    \n",
    "    user_message = f\"\"\"\n",
    "    The business problem is: {business_problem}. \\n\n",
    "    The dataset is expected to be in {dataset_format}. \n",
    "    For the text type return the generated dataset and the python code to write the output to the files.\n",
    "    If the generated dataset contains several entities, i.e. products, users, write the output for these entities into separate files. \n",
    "    The dependencies for python code should include only standard python libraries such as numpy, pandas and built-in libraries. \n",
    "    The output dataset is stored as a {file_format} file. \\n    \n",
    "    \"\"\"\n",
    "\n",
    "    return user_message\n",
    "\n",
    "def select_user_prompt(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_prompt = generate_user_prompt_text(business_problem, dataset_format, file_format)\n",
    "    if dataset_format in [\"Tabular\", \"Time-series\"]:\n",
    "        user_prompt = generate_user_prompt_tabular(business_problem, dataset_format, file_format, num_samples)\n",
    "    return user_prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443a42da-9b15-4608-bc14-d4d0eb824ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_prompt = select_user_prompt(business_problem, dataset_format, file_format, num_samples)\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages= [\n",
    "                    {\"role\": \"system\", \"content\":system_message},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt }\n",
    "                    ],\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "\n",
    "    return response\n",
    "\n",
    "def stream_claude(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_prompt = select_user_prompt(\n",
    "                    business_problem, dataset_format, file_format, num_samples\n",
    "                )\n",
    "    result = claude.messages.stream(\n",
    "            model=CLAUDE_MODEL,\n",
    "            max_tokens=2000,\n",
    "            system=system_message,\n",
    "            messages=[\n",
    "                {\"role\" : \"user\", \"content\": user_prompt }\n",
    "            ]\n",
    "        )\n",
    "    reply = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply\n",
    "        return reply\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b47e560-634e-4a5b-9cbb-29ee1e68081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(business_problem, dataset_format, file_format, num_samples, model):\n",
    "    if model == \"GPT\":\n",
    "        result = stream_gpt(business_problem, dataset_format, file_format, num_samples)\n",
    "    elif model == \"Claude\":\n",
    "        result = stream_claude(business_problem, dataset_format, file_format, num_samples)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a9ae67-0c0f-40d9-b8ab-f4615b0d00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching substring found.\n",
      "Output: \n",
      "Errors: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_code(text):\n",
    "    # Regular expression to find text between ``python and ``\n",
    "    match = re.search(r\"```python(.*?)```\", text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        code = match.group(0).strip()  # Extract and strip extra spaces\n",
    "    else:\n",
    "        code = \"\"\n",
    "        print(\"No matching substring found.\")\n",
    "\n",
    "    return code.replace(\"```python\\n\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "\n",
    "def execute_code_in_virtualenv(text, python_interpreter=sys.executable):\n",
    "    \"\"\"\n",
    "    Execute the given Python code string within the specified virtual environment.\n",
    "    \n",
    "    Args:\n",
    "    - code_str: str, the Python code to execute.\n",
    "    - venv_dir: str, the directory path to the virtual environment created by pipenv.\n",
    "    \"\"\"\n",
    "    # Construct the full path to the Python interpreter in the virtual environment\n",
    "    # python_interpreter = f\"{venv_dir}/bin/python\"\n",
    "\n",
    "    # Check if executing within the specified virtual environment interpreter\n",
    "    if not python_interpreter:\n",
    "        raise EnvironmentError(\"Python interpreter not found in the specified virtual environment.\")\n",
    "\n",
    "    # Prepare the command to execute the code\n",
    "    code_str = extract_code(text)\n",
    "    command = [python_interpreter, '-c', code_str]\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(\"Output:\", result.stdout)\n",
    "        print(\"Errors:\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while executing the code: {e}\")\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df906ee0-2908-4c56-a6a9-ee7f85f8d280",
   "metadata": {},
   "source": [
    "# Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e12da2-7be1-45f7-8c9f-462618fe709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## Create a dataset for a business problem\")\n",
    "    with gr.Column():\n",
    "        business_problem = gr.Textbox(label=\"Business problem\", lines=2)\n",
    "        dataset_type = gr.Dropdown(\n",
    "            [\"Tabular\", \"Time-series\", \"Text\"], label=\"Dataset modality\"\n",
    "        )\n",
    "        dataset_format = gr.Dropdown([\"JSON\", \"csv\", \"parquet\", \"Markdown\"], label=\"Output format\")\n",
    "        num_samples = gr.Number(label=\"Number of samples (for tabular and time-series data)\", value=10, precision=0)\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "    with gr.Row():\n",
    "        dataset_run = gr.Button(\"Create a dataset\")\n",
    "        code_run = gr.Button(\"Execute code for a dataset\")\n",
    "    with gr.Row():\n",
    "        dataset_out = gr.Textbox(label=\"Generated Dataset\")\n",
    "        code_out = gr.Textbox(label=\"Executed code\")\n",
    "    dataset_run.click(\n",
    "        generate_dataset,\n",
    "        inputs=[business_problem, dataset_type, dataset_format, num_samples, model],\n",
    "        outputs=[dataset_out]\n",
    "    )\n",
    "    code_run.click(execute_code_in_virtualenv, inputs=[dataset_out], outputs=[code_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba86368e-c92d-4cd6-9489-b3261690760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Generated synthetic customer profiles and saved to synthetic_customer_profiles.json.\n",
      "\n",
      "Errors: \n"
     ]
    }
   ],
   "source": [
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e839d38-e87f-4239-b5dd-47772c47103f",
   "metadata": {},
   "source": [
    "# Sample usage\n",
    "<img src=\"images/data_set_generator.png\" width=\"700\" height=\"500\" style=\"display: block;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cede87-0f5b-45f2-ae64-c27fd5c93b98",
   "metadata": {},
   "source": [
    "# Sample data generated\n",
    "[customer_data.json]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425a7c6-980e-48e5-9a57-4e55f72a587d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
