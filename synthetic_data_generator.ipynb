{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcbf162-873f-4609-807b-5976e32a3648",
   "metadata": {},
   "source": [
    "# Synthetic dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00dfc19-c054-4c1f-b6af-c98bb05bdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a963c5-5f74-429d-8e0c-76a43ef6e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b44bdc2-0903-4108-b5dc-f2f7a2fb9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "                    You are a dataset generation assistant specializing in creating high-quality synthetic datasets for AI training.\n",
    "                    Ensure data is realistic, diverse, and domain-specific.\n",
    "                    Do not include personally identifiable information (PII).\n",
    "                    Maintain logical consistency in relationships between fields.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d99fb5-5094-405c-8838-73e5d5b7c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt_tabular(business_problem, dataset_format, file_format, num_samples):\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    The business problem is: {business_problem}. \\n\n",
    "    The dataset is expected to be in {dataset_format}. \n",
    "    For the dataset types such as tabular or time series implement python code for creating the dataset.\n",
    "    If the generated dataset contains several entities, i.e. products, users, write the output for these entities into separate files. \n",
    "    The dependencies for python code should include only standard python libraries such as numpy, pandas and built-in libraries. \n",
    "    The output dataset is stored as a {file_format} file and contains {num_samples} samples. \\n    \n",
    "    \"\"\"\n",
    "\n",
    "    return user_message\n",
    "\n",
    "def generate_user_prompt_text(business_problem, dataset_format, file_format):\n",
    "    \n",
    "    user_message = f\"\"\"\n",
    "    The business problem is: {business_problem}. \\n\n",
    "    The dataset is expected to be in {dataset_format}. \n",
    "    For the text type return the generated dataset and the python code to write the output to the files.\n",
    "    If the generated dataset contains several entities, i.e. products, users, write the output for these entities into separate files. \n",
    "    The dependencies for python code should include only standard python libraries such as numpy, pandas and built-in libraries. \n",
    "    The output dataset is stored as a {file_format} file. \\n    \n",
    "    \"\"\"\n",
    "\n",
    "    return user_message\n",
    "\n",
    "def select_user_prompt(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_promot = \"\"\n",
    "    if dataset_format == \"Text\":\n",
    "        user_prompt = generate_user_prompt_text(business_problem, dataset_format, file_format)\n",
    "    elif dataset_format in [\"Tabular\", \"Time-series\"]:\n",
    "        user_prompt = generate_user_prompt_tabular(business_problem, dataset_format, file_format, num_samples)\n",
    "    return user_prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443a42da-9b15-4608-bc14-d4d0eb824ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_prompt = select_user_prompt(business_problem, dataset_format, file_format, num_samples)\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages= [\n",
    "                    {\"role\": \"system\", \"content\":system_message},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt }\n",
    "                    ],\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "\n",
    "    return response\n",
    "\n",
    "def stream_claude(business_problem, dataset_format, file_format, num_samples):\n",
    "    user_prompt = select_user_prompt(\n",
    "                    business_problem, dataset_format, file_format, num_samples\n",
    "                )\n",
    "    result = claude.messages.stream(\n",
    "            model=CLAUDE_MODEL,\n",
    "            max_tokens=2000,\n",
    "            system=system_message,\n",
    "            messages=[\n",
    "                {\"role\" : \"user\", \"content\": user_prompt }\n",
    "            ]\n",
    "        )\n",
    "    reply = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply\n",
    "        return reply\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b47e560-634e-4a5b-9cbb-29ee1e68081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(business_problem, dataset_format, file_format, num_samples, model):\n",
    "    if model == \"GPT\":\n",
    "        result = stream_gpt(business_problem, dataset_format, file_format, num_samples)\n",
    "    elif model == \"Claude\":\n",
    "        result = stream_claude(business_problem, dataset_format, file_format, num_samples)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a9ae67-0c0f-40d9-b8ab-f4615b0d00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_code(text):\n",
    "    # Regular expression to find text between ``python and ``\n",
    "    match = re.search(r\"```python(.*?)```\", text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        code = match.group(0).strip()  # Extract and strip extra spaces\n",
    "    else:\n",
    "        code = \"\"\n",
    "        print(\"No matching substring found.\")\n",
    "\n",
    "    return code.replace(\"```python\\n\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "\n",
    "def execute_code_in_virtualenv(text, python_interpreter=sys.executable):\n",
    "    \"\"\"\n",
    "    Execute the given Python code string within the specified virtual environment.\n",
    "    \n",
    "    Args:\n",
    "    - code_str: str, the Python code to execute.\n",
    "    - venv_dir: str, the directory path to the virtual environment created by pipenv.\n",
    "    \"\"\"\n",
    "    # Construct the full path to the Python interpreter in the virtual environment\n",
    "    # python_interpreter = f\"{venv_dir}/bin/python\"\n",
    "\n",
    "    # Check if executing within the specified virtual environment interpreter\n",
    "    if not python_interpreter:\n",
    "        raise EnvironmentError(\"Python interpreter not found in the specified virtual environment.\")\n",
    "\n",
    "    # Prepare the command to execute the code\n",
    "    code_str = extract_code(text)\n",
    "    command = [python_interpreter, '-c', code_str]\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(\"Output:\", result.stdout)\n",
    "        print(\"Errors:\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while executing the code: {e}\")\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df906ee0-2908-4c56-a6a9-ee7f85f8d280",
   "metadata": {},
   "source": [
    "# Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e12da2-7be1-45f7-8c9f-462618fe709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## Create a dataset for a business problem\")\n",
    "    with gr.Column():\n",
    "        business_problem = gr.Textbox(label=\"Business problem\", lines=2)\n",
    "        dataset_type = gr.Dropdown(\n",
    "            [\"Tabular\", \"Time-series\", \"Text\"], label=\"Dataset modality\"\n",
    "        )\n",
    "        dataset_format = gr.Dropdown([\"JSON\", \"csv\", \"parquet\", \"Markdown\"], label=\"Output format\")\n",
    "        num_samples = gr.Number(label=\"Number of samples (for tabular and time-series data)\", value=10, precision=0)\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "    with gr.Row():\n",
    "        dataset_run = gr.Button(\"Create a dataset\")\n",
    "        code_run = gr.Button(\"Execute code for a dataset\")\n",
    "    with gr.Row():\n",
    "        dataset_out = gr.Textbox(label=\"Generated Dataset\")\n",
    "        code_out = gr.Textbox(label=\"Executed code\")\n",
    "    dataset_run.click(\n",
    "        generate_dataset,\n",
    "        inputs=[business_problem, dataset_type, dataset_format, num_samples, model],\n",
    "        outputs=[dataset_out]\n",
    "    )\n",
    "    code_run.click(execute_code_in_virtualenv, inputs=[dataset_out], outputs=[code_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba86368e-c92d-4cd6-9489-b3261690760a",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while executing the code: Command '['/opt/anaconda3/envs/llms/bin/python', '-c', 'import numpy as np\\nimport pandas as pd\\nimport json\\nimport random\\nimport faker\\n\\n# Initialize Faker for generating realistic data\\nfake = faker.Faker()\\n\\n# Function to generate synthetic customer profiles\\ndef generate_customer_profiles(num_profiles):\\n    customer_profiles = []\\n\\n    for _ in range(num_profiles):\\n        profile = {\\n            \"customer_id\": fake.uuid4(),\\n            \"name\": fake.name(),\\n            \"age\": random.randint(18, 70),\\n            \"gender\": random.choice([\"Male\", \"Female\"]),\\n            \"email\": fake.email(),\\n            \"purchase_history\": generate_purchase_history(),\\n            \"membership_status\": random.choice([\"Basic\", \"Silver\", \"Gold\", \"Platinum\"])\\n        }\\n        customer_profiles.append(profile)\\n\\n    return customer_profiles\\n\\n# Function to generate synthetic purchase history\\ndef generate_purchase_history():\\n    products = [fake.bs() for _ in range(random.randint(1, 5))]  # Random product descriptions\\n    return random.sample(products, len(products))\\n\\n# Generate 10 customer profiles\\ncustomer_profiles = generate_customer_profiles(10)\\n\\n# Convert to DataFrame for better structure\\nprofiles_df = pd.DataFrame(customer_profiles)\\n\\n# Save the dataset as a JSON file\\noutput_file = \\'customer_profiles.json\\'\\nprofiles_df.to_json(output_file, orient=\\'records\\', lines=True)\\n\\nprint(f\"Generated customer profiles saved to {output_file}.\")\\n']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2044, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1591, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/s0/4nkd_hnd4ls5vmn9zhm_44680000gq/T/ipykernel_89442/3936812629.py\", line 40, in execute_code_in_virtualenv\n",
      "    return result.stdout\n",
      "           ^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'result' where it is not associated with a value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while executing the code: Command '['/opt/anaconda3/envs/llms/bin/python', '-c', 'import numpy as np\\nimport pandas as pd\\nimport json\\nimport random\\nimport faker\\n\\n# Initialize Faker for generating realistic data\\nfake = faker.Faker()\\n\\n# Function to generate synthetic customer profiles\\ndef generate_customer_profiles(num_profiles):\\n    customer_profiles = []\\n\\n    for _ in range(num_profiles):\\n        profile = {\\n            \"customer_id\": fake.uuid4(),\\n            \"name\": fake.name(),\\n            \"age\": random.randint(18, 70),\\n            \"gender\": random.choice([\"Male\", \"Female\"]),\\n            \"email\": fake.email(),\\n            \"purchase_history\": generate_purchase_history(),\\n            \"membership_status\": random.choice([\"Basic\", \"Silver\", \"Gold\", \"Platinum\"])\\n        }\\n        customer_profiles.append(profile)\\n\\n    return customer_profiles\\n\\n# Function to generate synthetic purchase history\\ndef generate_purchase_history():\\n    products = [fake.bs() for _ in range(random.randint(1, 5))]  # Random product descriptions\\n    return random.sample(products, len(products))\\n\\n# Generate 10 customer profiles\\ncustomer_profiles = generate_customer_profiles(10)\\n\\n# Convert to DataFrame for better structure\\nprofiles_df = pd.DataFrame(customer_profiles)\\n\\n# Save the dataset as a JSON file\\noutput_file = \\'customer_profiles.json\\'\\nprofiles_df.to_json(output_file, orient=\\'records\\', lines=True)\\n\\nprint(f\"Generated customer profiles saved to {output_file}.\")\\n']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2044, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1591, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/s0/4nkd_hnd4ls5vmn9zhm_44680000gq/T/ipykernel_89442/3936812629.py\", line 40, in execute_code_in_virtualenv\n",
      "    return result.stdout\n",
      "           ^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'result' where it is not associated with a value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Synthetic customer profiles generated and saved to 'synthetic_customer_profiles.json'\n",
      "\n",
      "Errors: \n"
     ]
    }
   ],
   "source": [
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e839d38-e87f-4239-b5dd-47772c47103f",
   "metadata": {},
   "source": [
    "# Sample usage\n",
    "<img src=\"images/data_set_generator.png\" width=\"700\" height=\"500\" style=\"display: block;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cede87-0f5b-45f2-ae64-c27fd5c93b98",
   "metadata": {},
   "source": [
    "# Sample data generated\n",
    "[customer_data.json]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425a7c6-980e-48e5-9a57-4e55f72a587d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
